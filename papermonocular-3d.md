|논문명|Monocular 3D Object Detection for Autonomous Driving
|-|-|
|저자(소속)|Xiaozhi Chen|
|학회/년도|CVPR 2016,  [논문](http://3dimage.ee.tsinghua.edu.cn/files/publications/CVPR16_XiaozhiChen.pdf)|
|키워드|MV3D 저자, KITTI, 후보영역 선출 |
|참고|[홈페이지](http://3dimage.ee.tsinghua.edu.cn/cxz/mono3d)|
|코드|[코드](http://3dimage.ee.tsinghua.edu.cn/files/XiaozhiChen/mono3d/mono3d_v1.2.tar.gz)|




# Monocular 3D 

![](http://3dimage.ee.tsinghua.edu.cn/files/XiaozhiChen/mono3d/mono3d_head.jpg)

목적 : perform 3D object detection from a single monocular image

Our method
1. first aims to generate a set of candidate class-specific `object proposals`
2. run a standard CNN pipeline to obtain high quality `object detections`

> `object proposals`에 좀더 중점을 두고 있음 

## 1. Introduction

자율주행차의 센서로 LIDAR를 많이 쓰지만, 비싼가격으로 최근에는 저렴한 Camera를 활용하는 방법에 대하여 연구 되고 있다. 

Faster R-CNN등의 물체 탐지 방법들은 후보영역을 선출하는 방법을 쓰고 있다. `Most of the recent object detection pipelines [19-Fast RCNN, 20-RCNN] typically proceed by generating adiverse set of object proposals that have a high recall and are relatively fast to compute [45, 2]. By doing this, computationally more intense classifiers such as CNNs [28, 42]can be devoted to a smaller subset of promising image regions, avoiding computation on a large set of futile candidates.`

```
[45] K. Van de Sande, J. Uijlings, T. Gevers, and A. Smeulders. Segmentation as selective search for object recognition. In ICCV, 2011
[2] P. Arbelaez, J. Pont-Tusetand, J. Barron, F. Marques, and J. Malik. Multiscale combinatorial grouping. In CVPR. 2014.
[28] A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012.
[42] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In arXiv:1409.1556, 2014.
```

### 1.1 object proposal methods

본 논문도 `후보영역` 아이디어를 활용한다. `Our paper follows this line of work. Different types of object proposal methods have been developed in the past few years. `


- 후보영역 선출의 일반적 방법은 `픽셀단위`로 나누고 `유사도`를 측정하는 것이다. `A common approach is to over-segment the image into super pixels and group these using several similarity measures [45, 2]. `

- `objectness`와 `contour`정보를 이용하여 윈도우 탐색하는 방법도 있다. `Approaches that efficiently explore an exhaustive set of windows using simple “objectness” features [1, 11], or contour information[55] have also been proposed.`

```
[1] B. Alexe, T. Deselares, and V. Ferrari. Measuring the objectness of image windows. PAMI, 2012.
[11] M. Cheng, Z. Zhang, M. Lin, and P. Torr. BING: Binarized normed gradients for objectness estimation at 300fps. In CVPR, 2014
[55] L. Zitnick and P. Dollar. Edge boxes: Locating object proposals from edges. In ECCV. 2014
```

- 최근에는 `세그멘테이션 모델`, `parametric energies`, `CNN Feature`를 사용하는 방법이 연구되고 있다.`The most recent line of work aims to learn how to propose promising object candidates using either ensembles of binary segmentation models [27], parametric energies [29] or window classifiers based on CNN features [18].`

```
[27] P. Kr ahenb uhl and V. Koltun. Learning to propose objects. In CVPR, 2015.
[29] T. Lee, S. Fidler, and S. Dickinson. A learning framework for generating region proposals with mid-level cues. In ICCV, 2015
[18] A. Ghodrati, A. Diba, M. Pedersoli, T. Tuytelaars, and L. V. Gool. Deepproposal: Hunting objects by cascading deep convolutional layers. In arXiv:1510.04445, 2015.
```

### 1.2 object proposal methods & KITTI Datasets

이러한 방식들은 PASCAL VOC에서는 좋은 성과를 보였다. 하지만, 자율주행의 경우에는 좀더 Strict한 룰이 적용 되어야 한다. 유명한 R-CNN같은 것들도 KITTI데이터에서는 성능이 않좋다. KITTI 데이터에서 좋은 성능을 보이는 [10]은 stereo imagery(2개의)을 이용하여서 3D 후보영역을 제안 한다. 
`The current leader on KITTI is Chen et al. [10], which exploits stereo imagery to create accurate 3D proposals.`

```
[10] X. Chen, K. Kundu, Y. Zhu, A. Berneshawi, H. Ma, S. Fidler, and R. Urtasun. 3d object proposals for accurate object class detection. In NIPS, 2015
```

하지만 대부분의 차량은 카메라가 한개 달려 있다.따라서  `monocular object detection` 는 중요한 도전 과제 이다. 

### 1.3 본 논문의 방식 

본 논문 제안 : this paper proposes a method that learns to generate class-specific 3D object proposals with very high recall by exploiting contextual models as well as semantics. 

These proposals are generated by exhaustively placing 3D bounding boxes on the ground-plane and scoring them via simple and efficiently computable image features. 

In particular, we use semantic and object instance segmentation, context, as well as shape features and location priors to score our boxes. 

We learn per-class weights for these features using S-SVM [24], adapting to each individual object class. 

The top object candidates are then scored with a CNN, resulting in the final set of detections. 

