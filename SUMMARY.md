# Summary

## Introduction

* [Introduction](README.md)
* [Vision-based SLAM](vision-based-slam.md)
* [Paper\_2017\_Survey\_CV4Vehicle \(50%\)](paper2017-survey.md)
* [Paper\_2017\_Overview of Services \(50%\)](paper2017-overview-of-services.md)
* [Paper\_2013\_Survey\_Vehicle Detection \(0%\)](paper2013-survey-vehicle-detection.md)
* [Paper\_2014\_Know\_limit\_stereo](paper2014-know-limit-stereo.md)
* [Paper\_2017\_3DCNN\_DQN\_RNN](paper20173dcnndqn-rnn.md)
* [Paper\_2016\_DL4SM](paper2016-dl4sm.md)
* [Paper\_2015\_DispNet](paper2015-dispnet.md)
* [Paper\_2017\_FlowNet2](paper2017-flownet2.md)

## Related Works

* [Papers\_OccupancyGridFusion](papersoccupancygridfusion.md)
  * [Paper\_2016\_MSF-OG \(5%\)](paper2016-msf-og.md)

## 2D CNN

* [Paper\_2017\_SqueezeDet \(50%\)](paper2016-squeezedet.md)

## 2.3D 2D to 3D Back-Projection

* [----- Monocular Vision -----](-monocular-vision-.md)
* [Intro\_MonocularVision](introback-projection.md)
* [Papers\_국내 논문\_단일카메라 \(100%\)](paperdepth-from-single-image/paper2015-b2e8-c77c-ce74-ba54-b77c-2-c7a5-c758-c774-bbf8-c9c0.md)
* [Paper\_2016\_Unify monocular detectors \(5%\)](paper2017-unify-monocular-detectors.md)
* [Paper\_2014\_DepthMap Prediction \(0%\)](paper2014-depthmap-prediction.md)
* [Paper\_2016\_Mono3D2016 \(70%\)](papermonocular-3d.md)
* [Paper\_2017\_Monocular Depth /w 2Camera \(0%\)](paper2016-monocular-depth.md)
* [Report\_2017\_Study\_Monocular \(70%\)](report2017-monocular-3-cnnmethods.md)
* [Paper\_2017\_Deep3DBox \(15%\)](paper2017-3d-bbox.md)
* [Paper\_2017\_J-MOD \(30%\)](paper2017-j-mod.md)
  * [Paper\_2017\_Domain Independent MDE  \(30%\)](paper2017-domain-independent-mde.md)
* [Paper\_2017\_Semi\_MDE \(0%\)](paper2017-semi-mde.md)
* [----- Stereo Vision -----](-stereo-vision-.md)
* [Intro\_StereoVision](introstereovision.md)
* [Paper\_2017\_3DOP\_X Chen \(70%\)](paper2017-3d-object-proposals.md)
  * [Paper\_2014\_SPS-Stereo \(30%\)](paper2014-sps-stereo.md)

## 3D PointCloud

* [Intro\_3D CloudPoint](intro3d-cloudpoint.md)
* [Paper\_2017\_Sruvey\_3D data\(100%\)](paper2017-sruvey-3d-data.md)
* [Paper\_2013\_Survey\_2D\_3DShape Descriptor \(30%\)](paper2016-deep-learning-representation.md)
* ----- Feature based -----
* [Paper\_2015\_DeepSD \(70%\)](paper2016-deep-learning-representation/paper2015-3d-deep-shape-descriptor.md)
  * [Paper\_2015\_DL Representation ](paper2016-deep-learning-representation/paper2015-dl-representation.md)
* [Paper\_2015\_3DMesh\_Laveling](paper2016-deep-learning-representation/paper2015-3dmesh-laveling.md)
* [----- Octree based -----](-octree-based-.md)
* [Paper\_2017\_OctNet \(30%\)](paper2017-octnet.md)
* ----- Volumetic based -----
* [Paper\_2015\_3D\_ShapeNet \(50%\)](paper2015-3d-shapenet.md)
* [Paper\_2015\_VoxNet \(70%\)](papervoxnet.md)
* [Paper\_2016\_V\_M CNNs \(70%\)](paper2016-volumetric-multiview-cnns.md)
* ----- Multiview based -----
* [Paper\_2015\_MVCNN \(70%\)](paper2015-mvcnn.md)
* [Paper\_2015\_DeepPano \(70%\)](paper2015-deeppano.md)
* [Paper\_2016\_pMVCNN \(30%\)](paper2016-pairwisemvcnn.md)
* [Paper\_2014\_AE3D shape Retrieval \(30%\)](paper2014-ae3d-shape-retrieval.md)
* [Paper\_2016\_VeloFCN\_Bo Li \(70%\)](paper2016-velofcn4vd.md)
* [Paper\_2016\_3D GAN](paper2016-3d-gan.md)
* [Paper\_2017\_LoDNN\_Road Detection \(10%\)](paper2017-lodnnroad-detection.md)
* [Paper\_2017\_SqueezeSeg](paper2017-squeezeseg.md)
* [Paper\_2016\_FPNN](paper2016-fpnn.md)
* ----- Pointcloud based -----
* [Paper\_2016\_PointNetDeep \(50%\)](paper2016-pointnet.md)
* [Paper\_2016\_PointNet3D \(50%\)](paper2016-pointnet3d.md)
* [Paper\_2016\_FCN4VD\_Bo Li  \(30%\)](paper3d-cnn.md)
* [Paper\_2017\_Vote3Deep \(50%\)](papervote3deep.md)
* [Point\_Cloud\_Data](pointcloud-data.md)
  * [ROS bags-TO-Image.ipynb](https://gist.github.com/anonymous/4857f8920c9fc901121a429ead32a7db)
  * [ROS bags-TO-Point Clods.ipynb](https://gist.github.com/anonymous/e675ea14113252be321320be62248034)
  * [ROS bags-TO-Avi.ipynb](https://gist.github.com/anonymous/fb1e98efe187b2a35b6d91fb5df9e83b)
  * [KITTI Dataset Exploration.ipynb](https://github.com/hunjung-lim/awesome-vehicle-datasets/blob/master/vehicle/kitti/KITTI%2BDataset%2BExploration.ipynb)
  * [KITTI Dataset Visualizing.ipynb](https://github.com/hunjung-lim/awesome-vehicle-datasets/blob/master/vehicle/kitti/KITTI%2BDataset%2BVisualizing.ipynb)
  * [Read\_RGBD](pointcloud-data/readrgbd.md)
  * [Velodyne\_LiDAR](pointcloud-data/velodynelidar.md)

## Fusion

* [----- Sensor Fusion 이란 -----](-sensor-fusion-c774-b780-.md)
* [Intro Sensor fusion](introfusion.md)
* [Papers\_RADAR\_Fusion](paper2013-radar-fusion.md)
* [Paper\_2011\_LateFusion \(0%\)](paper2011latefusion.md)
* [Paper\_2016\_FusionNet \(50%\)](paper2016-fusionnet.md)
* [Paper\_2016\_Fusing\_LIDAR\_IMAGE\_Pedestrian \(30%\)](paper2016-fusing-lidar-image-pedestrian.md)
* [Paper\_2016\_DeepSlidingShape \(30%\)](paper2016-deepslidingshape.md)
* [Paper\_2017\_Decision-Level Fusion \(50%\)](paper2017-decision-level-fusion.md)
* [Paper\_2017\_Sensor Modality Fusion \(50%\)](paper2017-sensor-modality-fusion.md)
* [Paper\_2017\_MV3D\(70%\)](papermultiview-3d-cnn.md)
  * [Code\_MV3D](papermultiview-3d-cnn/codemv3d.md)
  * [code\_MV3D\_TF](papermultiview-3d-cnn/codemv3d-tf.md)
* [Report\_2017\_cs231n\_Dempster-Shafer \(50%\)](report2017-cs231n-dempster-shafer.md)

## 4D \(Time, RNN\)

* [----- RNN based -----](-rnn-based-.md)
* [Paper\_2016\_3D-R2N2](paper2016-3d-r2n2.md)

## 참고

* [ref01\_Hardware](ref01hardware.md)
* [ref02\_Metrics](ref02metrics.md)
* [ref03\_Tracklet](ref03tracklet.md)
* ref04\_non-maxima suppression \(NMS\)

## Project

* [Project\_2017\_iPRoBe Lab](project2017-iprobe-lab.md)
* [Project\_2017\_Berkeley](project2017-berkeley.md)

